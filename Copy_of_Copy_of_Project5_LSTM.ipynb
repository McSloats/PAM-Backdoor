{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of Copy of Project5_LSTM.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/McSloats/PAM-Backdoor/blob/master/Copy_of_Copy_of_Project5_LSTM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IqmjxrEGLhom",
        "colab_type": "code",
        "outputId": "2cd965d7-2f13-487d-e577-9621f87df36c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_ZlymTSwrxPE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import scipy\n",
        "from keras.models import Sequential\n",
        "from keras.layers import LSTM\n",
        "from keras.layers import Embedding\n",
        "from keras.layers import Dropout\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Flatten\n",
        "from sklearn import preprocessing\n",
        "from keras import optimizers as op\n",
        "from keras.utils import to_categorical\n",
        "from keras.models import model_from_json\n",
        "from keras.callbacks import EarlyStopping\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CAwClx-6Dlqb",
        "colab_type": "code",
        "outputId": "6d2e492a-88cb-4236-81ae-fa409227c44b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        }
      },
      "source": [
        "##IMPORT FILE FOR DATA EXTRACTION\n",
        "benign = pd.read_csv(\"/content/drive/Shared drives/Machine Learning Project 5/benign.csv\")\n",
        "malicious = pd.read_csv(\"/content/drive/Shared drives/Machine Learning Project 5/malicious.csv\")\n"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py:2718: DtypeWarning: Columns (0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  interactivity=interactivity, compiler=compiler, result=result)\n",
            "/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py:2718: DtypeWarning: Columns (2,4,5,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  interactivity=interactivity, compiler=compiler, result=result)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vun2Ja96sKjB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#CREATE SINGLE DATAFRAME FOR BOTH THE BENIGN AND MALICIOUS DATA WITH MIXED ROWS\n",
        "benign = benign.sample(frac=1,random_state=1)\n",
        "malicious = malicious.sample(frac=1,random_state=1)\n",
        "data = [benign,malicious]\n",
        "data = pd.concat(data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KppaqOJxm8Ch",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "##INSERT SECTION FOR DATA PRE-PROCESSING \n",
        "x = data\n",
        "labels = list(x.columns.values)\n",
        "data = None\n",
        "benign = None \n",
        "malicious = None\n",
        "x = x.fillna(0)\n",
        "X = x.replace(np.inf, 0)\n",
        "x = None\n",
        "\n",
        "#IDENTIFY INDEXES OF LABELLED ENTRIES AND REMOVE THEM\n",
        "temp = X.to_numpy()\n",
        "index = []\n",
        "count  = 0 \n",
        "newArray = []\n",
        "for i in temp:\n",
        "  if \"Src Port\" in i:\n",
        "    index.append(count)\n",
        "  count += 1\n",
        "\n",
        "val = 0 \n",
        "for i in temp:\n",
        "  if val not in index:\n",
        "    newArray.append(i)\n",
        "  val += 1\n",
        "\n",
        "val = None\n",
        "X = None\n",
        "\n",
        "#SLICE 'N DICE\n",
        "#CHECK TO MAKE SURE LABELLED ENTRIES ARE REMOVED\n",
        "count = 0 \n",
        "for i in newArray:\n",
        "  if \"Src Port\" in i:\n",
        "    print(count)\n",
        "  count += 1\n",
        "\n",
        "#REMOVE INFINITY VALUES \n",
        "array = []\n",
        "for i in newArray:\n",
        "  if 'Infinity' in i:\n",
        "    temp = []\n",
        "    for j in i:\n",
        "      if j == 'Infinity':\n",
        "        temp.append(0)\n",
        "      else:\n",
        "        temp.append(j)\n",
        "    array.append(temp)\n",
        "  else:\n",
        "    array.append(i)\n",
        "newArray = array\n",
        "\n",
        "#Remove all zeroed entries or entries with no Flow ID \n",
        "new = []\n",
        "for i in newArray:\n",
        "  if i[0] != 0:\n",
        "    new.append(i)\n",
        "newArray = new\n",
        "temp = None\n",
        "\n",
        "df = pd.DataFrame(newArray,columns=labels)#Create new DF for data before removal and normalisation \n",
        "\n",
        "##DROP ATTRIBUTES FOR FEATURE SELECTION HERE \n",
        "df1 = df.drop(columns=labels[6]) # Timestamp\n",
        "labels = list(df1.columns.values)\n",
        "#print(list(df1.columns.values))\n",
        "df1 = df1.drop(columns=[labels[1],labels[3]]) # IP Addresses. --> TO CATEGORICAL \n",
        "labels = list(df1.columns.values)\n",
        "#print(\"Remaining Lables:\\n\",labels)\n",
        "\n",
        "Y = df1[labels[-1]]\n",
        "ids = df1[labels[0]]\n",
        "cats = ids\n",
        "X1 = df1.drop(columns=labels[0]) # Flow ID --> USE FOR PUTTING DATA TOGETHER FOR TIME SERIES\n",
        "X1 = X1.drop(columns=labels[-1])\n",
        "df = None\n",
        "df1 = None\n",
        "\n",
        "newY = []\n",
        "for i in Y:\n",
        "  if i == 'ben':\n",
        "    newY.append(0)\n",
        "  else:\n",
        "    newY.append(1)\n",
        "\n",
        "labelsNew = list(X1.columns.values)\n",
        "for col in labelsNew:\n",
        "  X1[col] = pd.to_numeric(X1[col])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nt9MBnM3VCP6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#NORMALISE DATA\n",
        "# Create a minimum and maximum processor object\n",
        "scaler = preprocessing.MinMaxScaler()\n",
        "\n",
        "# Create an object to transform the data to fit minmax processor\n",
        "x_scaled = scaler.fit_transform(X1)\n",
        "\n",
        "# Run the normalizer on the dataframe\n",
        "df_normalized = pd.DataFrame(x_scaled,columns=labelsNew)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q8P5KwUO1cNl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ids, _ = pd.factorize(cats)\n",
        "\n",
        "ids = pd.DataFrame(ids,columns=['Flow_ID'])\n",
        "\n",
        "# Create a minimum and maximum processor object\n",
        "min_max_scaler = preprocessing.MinMaxScaler()\n",
        "\n",
        "# Create an object to transform the data to fit minmax processor\n",
        "scaled = min_max_scaler.fit_transform(ids)\n",
        "\n",
        "ids = pd.DataFrame(scaled)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_-1xE7YFsNHg",
        "colab_type": "code",
        "outputId": "cabeedc9-00c0-4d95-8328-32bc0cc6d2dd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 442
        }
      },
      "source": [
        "Y = pd.DataFrame(newY,columns=['Label'])\n",
        "data = pd.concat([ids,df_normalized,Y],axis=1,sort=False) \n",
        "data = data.sample(frac=1).reset_index(drop=True)\n",
        "X = data.iloc[:,:-1].values\n",
        "Y = data.iloc[:,-1]\n",
        "print(X)\n",
        "print(Y)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[2.46936640e-01 8.83207446e-01 5.68245975e-02 ... 0.00000000e+00\n",
            "  0.00000000e+00 0.00000000e+00]\n",
            " [2.70689909e-01 3.58312352e-01 5.04463264e-02 ... 0.00000000e+00\n",
            "  0.00000000e+00 0.00000000e+00]\n",
            " [4.55951821e-01 2.12100404e-03 7.28679332e-01 ... 0.00000000e+00\n",
            "  0.00000000e+00 0.00000000e+00]\n",
            " ...\n",
            " [7.01693358e-01 7.34569314e-02 1.22072175e-03 ... 0.00000000e+00\n",
            "  0.00000000e+00 0.00000000e+00]\n",
            " [2.64062669e-01 1.22072175e-03 4.98191806e-01 ... 0.00000000e+00\n",
            "  0.00000000e+00 0.00000000e+00]\n",
            " [5.95400392e-01 4.18554971e-02 3.81475547e-04 ... 0.00000000e+00\n",
            "  0.00000000e+00 0.00000000e+00]]\n",
            "0         0\n",
            "1         0\n",
            "2         0\n",
            "3         0\n",
            "4         1\n",
            "         ..\n",
            "849863    1\n",
            "849864    0\n",
            "849865    1\n",
            "849866    0\n",
            "849867    1\n",
            "Name: Label, Length: 849868, dtype: int64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lzCeSiGMAOLZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.2)\n",
        "y_train = to_categorical(y_train)\n",
        "y_test = to_categorical(y_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O7lvHir3r9aE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def lstm(x_train, y_train):\n",
        "    #KERAS MODEL    \n",
        "    #create model\n",
        "    model = Sequential()\n",
        "    #get number of columns in training data\n",
        "    n_cols = x_train.shape[1]\n",
        "    #add model layers\n",
        "    model.add(Embedding(100000, 96,input_length=n_cols))\n",
        "    model.add(LSTM(192,return_sequences=True))\n",
        "    model.add(Dropout(0.2))\n",
        "    model.add(LSTM(96,return_sequences=True))\n",
        "    model.add(Dropout(0.2))\n",
        "    model.add(LSTM(48,return_sequences=True))\n",
        "    model.add(Dropout(0.2))\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(2, activation='sigmoid'))\n",
        "   \n",
        "    #Optimizer\n",
        "    opt = op.Adam()\n",
        "    #Compile model\n",
        "    model.compile(opt, loss='binary_crossentropy', \n",
        "                  metrics=['accuracy'])\n",
        "   \n",
        "    #TRAINING\n",
        "    #Put this var in callbacks to save model after each epoch\n",
        "    #checkpointer = ModelCheckpoint('model/model-{epoch:02d}.hdf5', verbose=1)\n",
        "\n",
        "    print(model.summary())\n",
        "    history = model.fit(x_train, y_train, batch_size=128, \n",
        "              validation_split=0.2, epochs=10)\n",
        "\n",
        "    return model, history\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KUXmAu9cEFay",
        "colab_type": "code",
        "outputId": "ed99ceda-f3e1-4d7e-e16b-22e39e6074ae",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 629
        }
      },
      "source": [
        "%%timeit\n",
        "model, history = lstm(x_train, y_train)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_5\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_5 (Embedding)      (None, 80, 96)            9600000   \n",
            "_________________________________________________________________\n",
            "lstm_13 (LSTM)               (None, 80, 192)           221952    \n",
            "_________________________________________________________________\n",
            "dropout_13 (Dropout)         (None, 80, 192)           0         \n",
            "_________________________________________________________________\n",
            "lstm_14 (LSTM)               (None, 80, 96)            110976    \n",
            "_________________________________________________________________\n",
            "dropout_14 (Dropout)         (None, 80, 96)            0         \n",
            "_________________________________________________________________\n",
            "lstm_15 (LSTM)               (None, 80, 48)            27840     \n",
            "_________________________________________________________________\n",
            "dropout_15 (Dropout)         (None, 80, 48)            0         \n",
            "_________________________________________________________________\n",
            "flatten_5 (Flatten)          (None, 3840)              0         \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 2)                 7682      \n",
            "=================================================================\n",
            "Total params: 9,968,450\n",
            "Trainable params: 9,968,450\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Train on 543915 samples, validate on 135979 samples\n",
            "Epoch 1/10\n",
            "543915/543915 [==============================] - 3661s 7ms/step - loss: 0.3459 - acc: 0.8355 - val_loss: 0.3377 - val_acc: 0.8435\n",
            "Epoch 2/10\n",
            "543915/543915 [==============================] - 3586s 7ms/step - loss: 0.3371 - acc: 0.8421 - val_loss: 0.3377 - val_acc: 0.8435\n",
            "Epoch 3/10\n",
            "543915/543915 [==============================] - 3593s 7ms/step - loss: 0.3358 - acc: 0.8434 - val_loss: 0.3367 - val_acc: 0.8435\n",
            "Epoch 4/10\n",
            "247552/543915 [============>.................] - ETA: 31:51 - loss: 0.3353 - acc: 0.8440"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZSCSsd68htGm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%timeit\n",
        "score = model.evaluate(x_test, y_test, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4uj2z55zok_P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn import metrics\n",
        "y_pred=model.predict(x_test)\n",
        "matrix = metrics.confusion_matrix(y_test.argmax(axis=1), y_pred.argmax(axis=1))\n",
        "print(matrix)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-cNFrUppZS-s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}